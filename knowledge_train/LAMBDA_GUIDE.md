# üöÄ Lambda Labs Quick Start Guide

–ë—ã—Å—Ç—Ä—ã–π –≥–∞–π–¥ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è External Brain 30M –Ω–∞ Lambda Labs GPU (H100).

## 1. –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Å—Ç–∞–Ω—Å–∞

1. –ó–∞–π–¥–∏ –Ω–∞ [lambda.cloud](https://cloud.lambdalabs.com/)
2. –í—ã–±–µ—Ä–∏ **1x H100** (–∏–ª–∏ 2x –¥–ª—è –±—ã—Å—Ç—Ä–µ–µ)
3. –ó–∞–ø—É—Å—Ç–∏ –∏–Ω—Å—Ç–∞–Ω—Å, –ø–æ–ª—É—á–∏ SSH –¥–æ—Å—Ç—É–ø

## 2. –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ

```bash
ssh ubuntu@<your-instance-ip>
```

## 3. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è

```bash
# –ö–ª–æ–Ω–∏—Ä—É–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
git clone https://github.com/ariannamethod/arianna.c.git
cd arianna.c/knowledge_train

# –°–æ–∑–¥–∞—ë–º –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
python3 -m venv venv
source venv/bin/activate

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install torch numpy pyyaml
```

## 4. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö

```bash
# –û—á–∏—Å—Ç–∫–∞ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è Wikipedia (~30 —Å–µ–∫—É–Ω–¥)
python prepare_data.py --input simplewiki_leads.txt --tokenizer ../weights/tokenizer.json

# –†–µ–∑—É–ª—å—Ç–∞—Ç: train.bin (~75 MB), val.bin (~4 MB)
```

## 5. –û–±—É—á–µ–Ω–∏–µ

```bash
# Lambda mode: –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è H100
python train.py --lambda_mode --out_dir out --max_iters 10000

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
#   --lambda_mode    : batch=128, bfloat16, torch.compile
#   --max_iters      : 10000 –∏—Ç–µ—Ä–∞—Ü–∏–π (~20-30 –º–∏–Ω—É—Ç)
#   --out_dir        : –ø–∞–ø–∫–∞ –¥–ª—è —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
```

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è

```bash
# –í –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ
watch -n 10 "ls -la out/*.pt"

# –ò–ª–∏ —Å–º–æ—Ç—Ä–∏ –ª–æ–≥–∏
tail -f train.log
```

## 6. –≠–∫—Å–ø–æ—Ä—Ç –≤–µ—Å–æ–≤

```bash
# –≠–∫—Å–ø–æ—Ä—Ç –≤ —Ñ–æ—Ä–º–∞—Ç arianna.c (float16 –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –º–µ—Å—Ç–∞)
python export.py out/external_brain_final.pt external_brain.bin --fp16

# –†–µ–∑—É–ª—å—Ç–∞—Ç: external_brain.bin (~60 MB)
```

## 7. –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞

```bash
# –ù–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–∞—à–∏–Ω–µ
scp ubuntu@<your-instance-ip>:~/arianna.c/knowledge_train/external_brain.bin ./weights/
```

## 8. –û—á–∏—Å—Ç–∫–∞

**–ù–ï –ó–ê–ë–£–î–¨ –í–´–ö–õ–Æ–ß–ò–¢–¨ –ò–ù–°–¢–ê–ù–°!** üí∏

```bash
# –ù–∞ lambda.cloud ‚Üí Instances ‚Üí Terminate
```

---

## üìä –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ |
|---------|----------|
| –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è | ~20-30 –º–∏–Ω |
| –°—Ç–æ–∏–º–æ—Å—Ç—å | ~$3-5 |
| –§–∏–Ω–∞–ª—å–Ω—ã–π loss | ~0.8-1.2 |
| –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ | ~60 MB (fp16) |

## üîß Troubleshooting

### CUDA out of memory
```bash
# –£–º–µ–Ω—å—à–∏ batch_size
python train.py --lambda_mode --batch_size 64
```

### –ú–µ–¥–ª–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
```bash
# –ü—Ä–æ–≤–µ—Ä—å —á—Ç–æ GPU –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
nvidia-smi
```

### –ü—Ä–µ—Ä–≤–∞–ª–æ—Å—å –æ–±—É—á–µ–Ω–∏–µ
```bash
# –ü—Ä–æ–¥–æ–ª–∂–∏ —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —á–µ–∫–ø–æ–∏–Ω—Ç–∞
python train.py --lambda_mode --resume out/checkpoint_5000.pt
```

---

## One-liner (–¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∑–∞–ø—É—Å–∫–∞)

```bash
cd arianna.c/knowledge_train && \
python prepare_data.py && \
python train.py --lambda_mode --out_dir out && \
python export.py out/external_brain_final.pt external_brain.bin --fp16
```

---

*Dubrovsky –±—ã–ª –Ω–∞—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω –∑–∞ 2 –º–∏–Ω—É—Ç—ã ‚Äî External Brain –∑–∞–π–º—ë—Ç —á—É—Ç—å –¥–æ–ª—å—à–µ –∏–∑-–∑–∞ –±–æ–ª—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ (30M vs 9M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤), –Ω–æ H100 —Å–ø—Ä–∞–≤–∏—Ç—Å—è! üî•*
