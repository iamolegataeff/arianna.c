# üöÄ Lambda Labs Quick Start Guide

–ë—ã—Å—Ç—Ä—ã–π –≥–∞–π–¥ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è External Brain 30M –Ω–∞ Lambda Labs GPU (H100).

## ‚ö†Ô∏è CRITICAL: Data/Params Ratio

**–ü–†–û–ß–ò–¢–ê–ô –ü–ï–†–ï–î –¢–†–ï–ù–ò–†–û–í–ö–û–ô!**

```
–ú–æ–¥–µ–ª—å: 29.58M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
–ú–∞–∫—Å–∏–º—É–º –¥–∞–Ω–Ω—ã—Ö: 15 MB (ratio 0.5:1)
–ë–µ–∑–æ–ø–∞—Å–Ω–æ: 10-12 MB (ratio 0.3-0.4:1)

‚ùå –°–¢–ê–†–´–ô –ü–û–î–•–û–î (75 MB) = ratio 2.5:1 = –ú–£–°–û–†
‚úÖ –ù–û–í–´–ô –ü–û–î–•–û–î (12 MB) = ratio 0.4:1 = –†–ê–ë–û–¢–ê–ï–¢
```

## 1. –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Å—Ç–∞–Ω—Å–∞

1. –ó–∞–π–¥–∏ –Ω–∞ [lambda.cloud](https://cloud.lambdalabs.com/)
2. –í—ã–±–µ—Ä–∏ **1x H100** (–∏–ª–∏ 2x –¥–ª—è –±—ã—Å—Ç—Ä–µ–µ)
3. –ó–∞–ø—É—Å—Ç–∏ –∏–Ω—Å—Ç–∞–Ω—Å, –ø–æ–ª—É—á–∏ SSH –¥–æ—Å—Ç—É–ø

## 2. –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ

```bash
ssh ubuntu@<your-instance-ip>
```

## 3. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è

```bash
# –ö–ª–æ–Ω–∏—Ä—É–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
git clone https://github.com/ariannamethod/arianna.c.git
cd arianna.c/knowledge_train

# –°–æ–∑–¥–∞—ë–º –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
python3 -m venv venv
source venv/bin/activate

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install torch numpy pyyaml
```

## 4. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–ò–°–ü–û–õ–¨–ó–£–ô –ü–†–ê–í–ò–õ–¨–ù–´–ô –°–ö–†–ò–ü–¢!)

```bash
# –í–ê–†–ò–ê–ù–¢ A: –§–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è (~12 MB, ratio 0.4:1)
python prepare_data_filtered.py --target-mb 12.0
# –†–µ–∑—É–ª—å—Ç–∞—Ç: data_filtered/train.bin (~12 MB), data_filtered/val.bin (~0.6 MB)

# –í–ê–†–ò–ê–ù–¢ B: Q&A —Ñ–æ—Ä–º–∞—Ç (~12 MB, ratio 0.4:1)
python prepare_data_qa.py --target-mb 12.0
# –†–µ–∑—É–ª—å—Ç–∞—Ç: data_qa/train.bin (~12 MB), data_qa/val.bin (~0.6 MB)

# ‚ö†Ô∏è –ù–ï –ò–°–ü–û–õ–¨–ó–£–ô —Å—Ç–∞—Ä—ã–π prepare_data.py - –æ–Ω —Å–æ–∑–¥–∞—ë—Ç 75 MB –º—É—Å–æ—Ä–∞!
```

## 5. –û–±—É—á–µ–Ω–∏–µ

```bash
# Lambda mode: –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è H100
# –î–ª—è Dataset A (filtered):
python train.py --lambda_mode --data_dir data_filtered --out_dir out_filtered --max_iters 10000

# –î–ª—è Dataset B (Q&A):
python train.py --lambda_mode --data_dir data_qa --out_dir out_qa --max_iters 10000

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
#   --lambda_mode    : batch=128, bfloat16, torch.compile
#   --max_iters      : 10000 –∏—Ç–µ—Ä–∞—Ü–∏–π (~20-30 –º–∏–Ω—É—Ç)
#   --data_dir       : –ø–∞–ø–∫–∞ —Å train.bin/val.bin
#   --out_dir        : –ø–∞–ø–∫–∞ –¥–ª—è —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
```

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è

```bash
# –í –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ
watch -n 10 "ls -la out/*.pt"

# –ò–ª–∏ —Å–º–æ—Ç—Ä–∏ –ª–æ–≥–∏
tail -f train.log
```

## 6. –≠–∫—Å–ø–æ—Ä—Ç –≤–µ—Å–æ–≤

```bash
# –≠–∫—Å–ø–æ—Ä—Ç –≤ —Ñ–æ—Ä–º–∞—Ç arianna.c (float16 –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –º–µ—Å—Ç–∞)
python export.py out/external_brain_final.pt external_brain.bin --fp16

# –†–µ–∑—É–ª—å—Ç–∞—Ç: external_brain.bin (~60 MB)
```

## 7. –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞

```bash
# –ù–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–∞—à–∏–Ω–µ
scp ubuntu@<your-instance-ip>:~/arianna.c/knowledge_train/external_brain.bin ./weights/
```

## 8. –û—á–∏—Å—Ç–∫–∞

**–ù–ï –ó–ê–ë–£–î–¨ –í–´–ö–õ–Æ–ß–ò–¢–¨ –ò–ù–°–¢–ê–ù–°!** üí∏

```bash
# –ù–∞ lambda.cloud ‚Üí Instances ‚Üí Terminate
```

---

## üìä –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

| –ú–µ—Ç—Ä–∏–∫–∞ | –°—Ç–∞—Ä—ã–π (–ü–õ–û–•–û) | –ù–æ–≤—ã–π (–ü–†–ê–í–ò–õ–¨–ù–û) |
|---------|----------------|-------------------|
| –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö | 75 MB | 12 MB |
| Data/Params ratio | 2.5:1 ‚ùå | 0.4:1 ‚úÖ |
| –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è | ~30 –º–∏–Ω | ~20 –º–∏–Ω |
| –°—Ç–æ–∏–º–æ—Å—Ç—å | ~$5 | ~$3 |
| –§–∏–Ω–∞–ª—å–Ω—ã–π loss | ~1.5 | ~0.8-1.0 |
| –ö–∞—á–µ—Å—Ç–≤–æ | "Einstein was a financial authority" üíÄ | "Einstein was a physicist" ‚úÖ |

## üîß Troubleshooting

### CUDA out of memory
```bash
# –£–º–µ–Ω—å—à–∏ batch_size
python train.py --lambda_mode --batch_size 64
```

### –ú–µ–¥–ª–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
```bash
# –ü—Ä–æ–≤–µ—Ä—å —á—Ç–æ GPU –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
nvidia-smi
```

### –ü—Ä–µ—Ä–≤–∞–ª–æ—Å—å –æ–±—É—á–µ–Ω–∏–µ
```bash
# –ü—Ä–æ–¥–æ–ª–∂–∏ —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —á–µ–∫–ø–æ–∏–Ω—Ç–∞
python train.py --lambda_mode --resume out/checkpoint_5000.pt
```

---

## One-liner (–¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∑–∞–ø—É—Å–∫–∞)

```bash
cd arianna.c/knowledge_train && \
python prepare_data.py && \
python train.py --lambda_mode --out_dir out && \
python export.py out/external_brain_final.pt external_brain.bin --fp16
```

---

*Dubrovsky –±—ã–ª –Ω–∞—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω –∑–∞ 2 –º–∏–Ω—É—Ç—ã ‚Äî External Brain –∑–∞–π–º—ë—Ç —á—É—Ç—å –¥–æ–ª—å—à–µ –∏–∑-–∑–∞ –±–æ–ª—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ (30M vs 9M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤), –Ω–æ H100 —Å–ø—Ä–∞–≤–∏—Ç—Å—è! üî•*
